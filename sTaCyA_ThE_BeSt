import re
import urllib.request
import html


def function_1(website): 
    req = urllib.request.Request(website)
    with urllib.request.urlopen(req) as response:
        html_page = response.read().decode('utf-8')
        
    return html_page# eto text1
        
        
A = []
def clean_text1():
    list_of_articles = ["http://runews24.ru/culture/03/12/2016/0b1e9ad3de5d3a866840728cb5fe9110",
                        "http://www.vesti.ru/doc.html?id=2828727"]
    for i in list_of_articles:
        webpage = function_1(i)
        text = re.search ('<div (class="desc text"|class="js-mediator-article")>(.*?)</div>'
                            , webpage, flags = re.DOTALL)#eto regtext1
        text_cleansed = re.findall(text.group(2),webpage)
        new_element = text_cleansed
        A.append(new_element)
        
    return text_cleansed


        
def process(text_cleansed):
    
        regDiv = re.compile('<div.*?>.*?</div>', flags=re.DOTALL)
        regTag = re.compile('<.*?>', flags=re.DOTALL) 
        regScript = re.compile('<script.*?>.*?</script>', flags=re.DOTALL) 
        regComment = re.compile('<!--.*?-->', flags=re.DOTALL) 
        regSpace = re.compile('\s{2,}', flags = re.DOTALL)
        good_text= []
        
        for t in text_cleansed:
            clean_text = regSpace.sub(" ", t)
            clean_text = regDiv.sub(" ", clean_text)
            clean_text = regScript.sub(" ", clean_text)
            clean_text = regTag.sub(" ", clean_text)
            clean_text = regComment.sub(" ", clean_text)
            clean_text = html.unescape(clean_text)
            good_text.append(clean_text)
            
            for t in good_text:
                a = t.split(' ')
                listik = []
                for elem in a:
                    elem = elem.strip(',./\?":;!@#$%^&*()-_=+»«"1—234567890\n\t\xa0')
                    elem = elem.lower()
                    if elem !='':
                        listik.append(elem)
                q = set(listik)
                
            return q

def per():
    text_cleansed = clean_text1()
    q = process(text_cleansed)
    z = q.copy()
    for k in A:
        stroka = k
        q =  process(k)
        o = q.copy()
        z = o & z
    p = z.copy()
    x = list(p)
    x.sort()
    q_c = x
    return(q_c)
        
def obj():
    text_cleansed = clean_text1()
    q = process(text_cleansed)
    z = q.copy()
    for k in A:
        stroka = k
        q =  process(k)
        o = q.copy()
        z = o | z
    p = z.copy()
    x = list(p)
    x.sort()
    q_d = x
    return(q_d)

def sim_raz():
    
    b = set(obj()) ^ set(per())
    c = list(b)
    c.sort()
    return (c)
        
    
def write_difference(q_d,name):
    fw = open(name, 'w', encoding = 'utf-8')
    fw.write(str(q_d) + '\n')
    fw.close()
    
def write_common(q_c,name):
    fw = open(name, 'w', encoding = 'utf-8')
    fw.write(str(q_c) + '\n')
    fw.close()




def main ():
    
    print(sim_raz())
    
    #write_common(spot_the_common(), 'пересечение.txt')
    #write_common(spot_the_difference(), 'симм-разность.txt')
   
        
if __name__ == '__main__':
    main()
        
